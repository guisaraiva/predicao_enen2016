# -*- coding: utf-8 -*-
"""predicao_enem_2016.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MU16qjUI6z38Sob44nKGcXhbeG9WTucu
"""

'''
Importação das bibliotecas que serão utilizadas para análise dos dados
e predição da nota de Matemática no arquivo de teste.

'''
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

'''
Lendo os arquivos disponibilizados no desafio. Estou usando o metódo read_csv da biblioteca pandas.
Armazeno cada arquivo em variáveis distintas.

'''

data_train = pd.read_csv('/content/drive/My Drive/datasets/train.csv', sep="," , encoding="UTF8" )
data_test = pd.read_csv('/content/drive/My Drive/datasets/test.csv', sep="," , encoding="UTF8" )

'''
Utilizei a função colums para verificar quais as colunas existentes no
arquivo de teste.
'''

data_test.columns

'''
Utilizei a função corr() para verificar a correção de todas as 
features existentes no arquivo de treino.

Não temos como realizar este procedimento no arquivo de teste. Pois não 
temos a variável target no arquivo de teste.
'''

data_train.corr()

'''
Após analisar o dicionário de dados do desafio, identifiquei algumas features
que tem forte correlação com a variável Target.

Criei duas variáveis para armazer as features de cada arquivo de dados.

A diferença é a variável target no arquivo de treino.

'''


features_test = ['NU_NOTA_CN','NU_NOTA_CH','NU_NOTA_LC','NU_NOTA_REDACAO','NU_NOTA_COMP1','NU_NOTA_COMP2', 'NU_NOTA_COMP3','NU_NOTA_COMP4', 'NU_NOTA_COMP5']

features_train = ['NU_NOTA_MT','NU_NOTA_CN','NU_NOTA_CH','NU_NOTA_LC','NU_NOTA_REDACAO','NU_NOTA_COMP2', 'NU_NOTA_COMP3','NU_NOTA_COMP4', 'NU_NOTA_COMP5']

'''
Verificando quais features possuem valores nulos na base de dados.

A verificação é feita nos dados de treino e teste.
'''

data_train[features_test].isnull().sum()
data_train[features_train].isnull().sum()

'''
Realizo outra análise de correlação nos dados de treino.

Desta vez, utilizo a biblioteca matplotlib para visualizar as 
informações em forma de gráfico.

Visualmente, fica muito melhor entender a correção desta forma.

A documentação do heatmap é fantástica. Vale a pena dar uma olhada.
'''

corr = df_train[features_train].corr()
ax = plt.subplots(figsize=(12, 8))
sns.heatmap(corr,  annot=True, cmap="YlGnBu" ,annot_kws={"size": 10})

'''
Agora, eu faço as variáveis (data) receber o seu conteúdo novamente. Mas passando
uma condição que não retorne os dados com valores nulos e zerados.

São dados dispensáveis para a minha análise.
'''

data_train = data_train.loc[
      (data_train['NU_NOTA_CN'].notnull())  & (data_train['NU_NOTA_CN'] != 0) & (data_train['NU_NOTA_CH'].notnull())      & (data_train['NU_NOTA_CH'] != 0) 
    & (data_train['NU_NOTA_LC'].notnull())  & (data_train['NU_NOTA_LC'] != 0) & (data_train['NU_NOTA_REDACAO'].notnull()) & (data_train['NU_NOTA_REDACAO'] != 0)    
    
]
data_test = data_test.loc[
      (data_test['NU_NOTA_CN'].notnull())  & (data_test['NU_NOTA_CN'] != 0) & (data_test['NU_NOTA_CH'].notnull())      & (data_test['NU_NOTA_CH'] != 0) 
    & (data_test['NU_NOTA_LC'].notnull())  & (data_test['NU_NOTA_LC'] != 0) & (data_test['NU_NOTA_REDACAO'].notnull()) & (data_test['NU_NOTA_REDACAO'] != 0)    
]

'''
Verificando se ainda existem valores nulos.
'''

data_test[features_test].isnull().sum()
#data_train[features_train].isnull().sum()

'''
As demais features dos meus arquivos de dados que possuem valores nulos, realizo
a atribuição do valor zero para que possa usá-las na análise.
'''

data_test['NU_NOTA_COMP1'].fillna(0,inplace=True)
data_test['NU_NOTA_COMP2'].fillna(0,inplace=True)
data_test['NU_NOTA_COMP3'].fillna(0,inplace=True)
data_test['NU_NOTA_COMP4'].fillna(0,inplace=True)
data_test['NU_NOTA_COMP5'].fillna(0,inplace=True)
data_train['NU_NOTA_COMP1'].fillna(0,inplace=True)
data_train['NU_NOTA_COMP2'].fillna(0,inplace=True)
data_train['NU_NOTA_COMP3'].fillna(0,inplace=True)
data_train['NU_NOTA_COMP4'].fillna(0,inplace=True)
data_train['NU_NOTA_COMP5'].fillna(0,inplace=True)

'''
Vamos começar a brincadeira nesse bloco de instrução.

Podemos reparar a criação de variáveis de treino e de teste.

Estou isolando a variável target das demais features para começar o treinamento
do meu algoritmo.

Estou padronizando os dados utilizando o StandardScaler.

Documentação:
https://scikit-learn.org/stable/modules/preprocessing.html

'''


y_train = data_train['NU_NOTA_MT']
x_train = data_train[features_train]
x_test = data_test[features_test]

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()  
x_train = sc.fit_transform(x_train)  
x_test = sc.transform(x_test)

'''
Utilizei RandomForestRegressor para estimar os respectivos valores do aquivo de
teste.

Os parâmetros precisam ser adequados ao resultado esperado.

Realizei várias alterações nos parâmetros para exportar melhores resultados.

Mais detalhes na documento:

https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html
'''


from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor( 
           criterion='mae', 
           max_depth=8,
           max_leaf_nodes=None,
           min_impurity_split=None,
           min_samples_leaf=1,
           min_samples_split=2,
           min_weight_fraction_leaf=0.0,
           n_estimators= 500,
           n_jobs=-1,
           random_state=0,
           verbose=0,
           warm_start=False
)

'''
Treinando o modelo de predição com a variável target usand o fit.

Observe que a variável regressor foi construída anteriormente. 
'''

regressor.fit(x_train, y_train)

'''
Prevendo a variável target com os dados do arquivo de teste.
'''

y_pred_test = regressor.predict(x_test)

'''
Visualizando os 10 primeiros registros da predição.
'''

y_pred_test[:10]

'''
Criando um Data Frame (Pandas) para armazenar apenas a coluna NUM_NOTA_MT e NUM_INSCRICAO.
'''

data_resp = pd.DataFrame()

''' 
Criando as colunas no Data Frame com os valores desejados.
Observe que estou atribuindo os dados em cada posição do dataframe.
'''

data_resp ['NU_INSCRICAO'] = data_test['NU_INSCRICAO']
data_resp ['NU_NOTA_MT']=y_pred_test

'''
Exportar os resultados para formato CSV.

Eu passo o caminho em que o arquivo deve ser salvo com seus respectivo nome e extensão. 

Realizo a exclusão da coluna "Index". Só quero os dados das colunas NUM_NOTA_MT e NUM_INSCRICAO.

'''

data_resp.to_csv(r'/content/drive/My Drive/datasets/answer.csv', index=False)

